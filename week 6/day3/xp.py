# -*- coding: utf-8 -*-
"""xp

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oUOUcVfDUUMbp8N3chCGdAOU5b_YDFAe

Exercise 1 : Parsing HTML with BeautifulSoup
Instructions
Objective: Use urlopen() to fetch the HTML content of a webpage and then parse it using BeautifulSoup.
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sports World</title>
    <style>
        body { font-family: Arial, sans-serif; }
        header, nav, section, article, footer { margin: 20px; padding: 15px; }
        nav { background-color: #333; }
        nav a { color: white; padding: 14px 20px; text-decoration: none; display: inline-block; }
        nav a:hover { background-color: #ddd; color: black; }
        .video { text-align: center; margin: 20px 0; }
    </style>
</head>
<body>

    <header>
        <h1>Welcome to Sports World</h1>
        <p>Your one-stop destination for the latest sports news and videos.</p>
    </header>

    <nav>
        <a href="#football">Football</a>
        <a href="#basketball">Basketball</a>
        <a href="#tennis">Tennis</a>
    </nav>

    <section id="football">
        <h2>Football</h2>
        <article>
            <h3>Latest Football News</h3>
            <p>Read about the latest football matches and player news.</p>
            <div class="video">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/football-video-id" frameborder="0" allowfullscreen>
                </iframe>
            </div>
        </article>
    </section>

    <section id="basketball">
        <h2>Basketball</h2>
        <article>
            <h3>NBA Highlights</h3>
            <p>Watch highlights from the latest NBA games.</p>
            <div class="video">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/basketball-video-id" frameborder="0" allowfullscreen>
                </iframe>
            </div>
        </article>
    </section>

    <section id="tennis">
        <h2>Tennis</h2>
        <article>
            <h3>Grand Slam Updates</h3>
            <p>Get the latest updates from the world of Grand Slam tennis.</p>
            <div class="video">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/tennis-video-id" frameborder="0" allowfullscreen></iframe>
            </div>
        </article>
    </section>

    <footer>
        <form action="mailto:contact@sportsworld.com" method="post" enctype="text/plain">
            <label for="name">Name:</label><br>
            <input type="text" id="name" name="name"><br>
            <label for="email">Email:</label><br>
            <input type="email" id="email" name="email"><br>
            <label for="message">Message:</label><br>
            <textarea id="message" name="message" rows="4" cols="50"></textarea><br><br>
            <input type="submit" value="Send">
        </form>
    </footer>

</body>
</html>




Read the HTML content of the page.
Create a BeautifulSoup object to parse this HTML.
Find the title of the webpage (the content inside the <title> tag).
Extract all paragraphs (<p> tags) from the page.
Retrieve all links (URLs in <a href=""> tags) on the page.
"""

from urllib.request import urlopen
from bs4 import BeautifulSoup

# Assuming the HTML content is stored in a file named 'sports_world.html'
with open('sports_world.html', 'r') as f:
    html_content = f.read()

# Create a BeautifulSoup object to parse the HTML
soup = BeautifulSoup(html_content, 'html.parser')

# Find the title of the webpage
title = soup.title.string
print("Title:", title)

# Extract all paragraphs
paragraphs = soup.find_all('p')
print("\nParagraphs:")
for paragraph in paragraphs:
    print(paragraph.text)

# Retrieve all links
links = soup.find_all('a')
print("\nLinks:")
for link in links:
    print(link.get('href'))

"""
ðŸŒŸ Exercise 2 : Scraping robots.txt from Wikipedia
Instructions
Write a Python program to download and display the content of robot.txt for wikipedia



"""

# prompt: write a python program to download and dispaly the content of robot.txt

from urllib.request import urlopen

def download_robots_txt(url):
  """Downloads and displays the content of robots.txt for a given URL."""
  try:
    robots_url = url + "/robots.txt"
    response = urlopen(robots_url)
    content = response.read().decode('utf-8')
    print(content)
  except Exception as e:
    print(f"Error downloading robots.txt: {e}")

if __name__ == "__main__":
  target_url = "https://www.wikipedia.org"
  download_robots_txt(target_url)

"""
ðŸŒŸ Exercise 3 : Extracting Headers from Wikipediaâ€™s Main Page
Instructions
Write a Python program to extract and display all the header tags from wikipedia.



"""

# prompt: extract headers from wikipedias main page

from urllib.request import urlopen
from bs4 import BeautifulSoup

def extract_headers_from_wikipedia():
  """Extracts and displays all header tags from Wikipedia's main page."""
  try:
    url = "https://www.wikipedia.org"
    response = urlopen(url)
    html_content = response.read().decode('utf-8')
    soup = BeautifulSoup(html_content, 'html.parser')
    headers = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
    for header in headers:
      print(header.text)
  except Exception as e:
    print(f"Error extracting headers: {e}")


if __name__ == "__main__":
  extract_headers_from_wikipedia()

"""
ðŸŒŸ Exercise 4 : Checking for Page Title
Instructions
Write a Python program to check whether a page contains a title or not.

"""

from urllib.request import urlopen
from bs4 import BeautifulSoup

def check_page_title(url):
  """Checks if a webpage has a title."""
  try:
    response = urlopen(url)
    html_content = response.read().decode('utf-8')
    soup = BeautifulSoup(html_content, 'html.parser')
    title = soup.title
    if title:
      print("The page has a title:", title.string)
    else:
      print("The page does not have a title.")
  except Exception as e:
    print(f"Error checking page title: {e}")


if __name__ == "__main__":
  target_url = "https://www.wikipedia.org"
  check_page_title(target_url)

"""Exercise 5 : Analyzing US-CERT Security Alerts
Instructions
Write a Python program to get the number of security alerts issued by US-CERT in the current year.
Source


"""

# prompt: write a python program to get the number of security alerts issued by us_cert in the currnt year

from datetime import datetime
from urllib.request import urlopen
from bs4 import BeautifulSoup

def get_us_cert_alerts_count():
  """Gets the number of US-CERT alerts issued in the current year."""
  try:
    url = "https://www.cisa.gov/uscert/ncas/alerts"
    response = urlopen(url)
    html_content = response.read().decode('utf-8')
    soup = BeautifulSoup(html_content, 'html.parser')

    current_year = datetime.now().year
    alert_count = 0

    # Find all the alert elements (adjust based on the website structure)
    for alert in soup.find_all('div', class_='alert-content'):
      # Extract the date from the alert
      date_string = alert.find('time')['datetime']
      try:
        alert_date = datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S.%fZ')
      except ValueError:
        alert_date = datetime.strptime(date_string, '%Y-%m-%d')

      if alert_date.year == current_year:
        alert_count += 1

    return alert_count

  except Exception as e:
    print(f"Error fetching US-CERT alerts: {e}")
    return 0

if __name__ == "__main__":
  alert_count = get_us_cert_alerts_count()
  print(f"Number of US-CERT alerts in {datetime.now().year}: {alert_count}")

"""Exercise 6 : Scraping Movie Details
Instructions
Write a Python program to get movie name, year and a brief summary of the top 10 random movies from this IMBD website.




"""

from urllib.request import urlopen
from bs4 import BeautifulSoup
import random

def get_movie_details(url):
  """Fetches movie details from a given IMDB movie URL."""
  try:
    response = urlopen(url)
    html_content = response.read().decode('utf-8')
    soup = BeautifulSoup(html_content, 'html.parser')

    title = soup.find('h1').text.strip()
    year_element = soup.find('span', {'id': 'titleYear'})
    year = year_element.text[1:-1] if year_element else 'N/A'
    summary = soup.find('div', {'class': 'summary_text'}).text.strip()

    return title, year, summary

  except Exception as e:
    print(f"Error fetching movie details: {e}")
    return None, None, None

def main():
  """Fetches and displays details of 10 random movies from IMDB."""
  base_url = "https://www.imdb.com/title/tt"

  for _ in range(10):
    random_movie_id = ''.join(random.choices('0123456789', k=7))
    movie_url = f"{base_url}{random_movie_id}/"

    title, year, summary = get_movie_details(movie_url)

    if title:
      print("-" * 20)
      print(f"Title: {title}")
      print(f"Year: {year}")
      print(f"Summary: {summary}")
      print("-" * 20)
    else:
      print(f"Unable to fetch details for movie ID: {random_movie_id}")


if __name__ == "__main__":
  main()