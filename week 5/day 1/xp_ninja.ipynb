{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1 : Evaluation Metrics Implementation\n",
        "Objective:\n",
        "Implement Python functions to calculate Accuracy, Precision, Recall, and F1-Score from scratch.\n",
        "\n",
        "Dataset:\n",
        "Use any binary classification dataset, for example, the Breast Cancer Wisconsin (Diagnostic) dataset available in scikit-learn or any other binary classification dataset of your choice.\n",
        "\n",
        "Tasks:\n",
        "Split the dataset into training and test sets.\n",
        "Train a simple classification model (like Logistic Regression) on the training set.\n",
        "Make predictions on the test set.\n",
        "Write functions to calculate Accuracy, Precision, Recall, and F1-Score using the confusion matrix components (TP, TN, FP, FN).\n",
        "Evaluate your model using these metrics and interpret the results.\n"
      ],
      "metadata": {
        "id": "lLmZH0n-fFSC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y009hOdHfCxy",
        "outputId": "70296e67-8ac4-4f75-e500-1d3513aac7a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9707602339181286\n",
            "Precision: 0.963963963963964\n",
            "Recall: 0.9907407407407407\n",
            "F1-Score: 0.9771689497716894\n",
            "\n",
            "Accuracy gives the proportion of correct predictions among the total number of cases.\n",
            "Precision tells us the proportion of positive identifications that were actually correct.\n",
            "Recall gives the proportion of actual positives that were correctly identified.\n",
            "F1-Score provides a balance between Precision and Recall.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Get confusion matrix components\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "# Function to calculate Accuracy\n",
        "def calculate_accuracy(tp, tn, fp, fn):\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "    return accuracy\n",
        "\n",
        "# Function to calculate Precision\n",
        "def calculate_precision(tp, fp):\n",
        "    precision = tp / (tp + fp)\n",
        "    return precision\n",
        "\n",
        "# Function to calculate Recall\n",
        "def calculate_recall(tp, fn):\n",
        "    recall = tp / (tp + fn)\n",
        "    return recall\n",
        "\n",
        "# Function to calculate F1-Score\n",
        "def calculate_f1_score(precision, recall):\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1_score\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = calculate_accuracy(tp, tn, fp, fn)\n",
        "precision = calculate_precision(tp, fp)\n",
        "recall = calculate_recall(tp, fn)\n",
        "f1_score = calculate_f1_score(precision, recall)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1_score}\")\n",
        "interpretation = \"\"\"\n",
        "Accuracy gives the proportion of correct predictions among the total number of cases.\n",
        "Precision tells us the proportion of positive identifications that were actually correct.\n",
        "Recall gives the proportion of actual positives that were correctly identified.\n",
        "F1-Score provides a balance between Precision and Recall.\n",
        "\"\"\"\n",
        "\n",
        "print(interpretation)"
      ]
    }
  ]
}