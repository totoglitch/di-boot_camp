{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Exercise 1: Duplicate Detection and Removal\n",
        "Instructions\n",
        "Objective: Identify and remove duplicate entries in the Titanic dataset.\n",
        "\n",
        "Load the Titanic dataset.\n",
        "Identify if there are any duplicate rows based on all columns.\n",
        "Remove any duplicate rows found in the dataset.\n",
        "Verify the removal of duplicates by checking the number of rows before and after the duplicate removal.\n",
        "Hint: Use the duplicated() and drop_duplicates() functions in Pandas.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9X77PuzW3FXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df1=pd.read_csv(\"/content/train.csv\")\n",
        "df1\n",
        "df2=pd.read_csv(\"/content/test.csv\")\n",
        "df2\n",
        "df3=pd.read_csv(\"/content/gender_submission.csv\")\n",
        "df3\n",
        "df1.isnull().sum()\n",
        "df2.isnull().sum()\n",
        "df3.isnull().sum()\n",
        "df1.duplicated().sum()\n",
        "df2.duplicated().sum()\n",
        "df3.duplicated().sum()\n",
        "df1.drop_duplicates(inplace=True)\n",
        "df2.drop_duplicates(inplace=True)\n",
        "df3.drop_duplicates(inplace=True)\n",
        "df1.duplicated().sum()\n",
        "df2.duplicated().sum()\n",
        "df3.duplicated().sum()\n",
        "print(\"Number of rows in df1 before removing duplicates:\", df1.shape[0])\n",
        "df1.drop_duplicates(inplace=True)\n",
        "print(\"Number of rows in df1 after removing duplicates:\", df1.shape[0])\n",
        "print(\"Number of rows in df2 before removing duplicates:\", df2.shape[0])\n",
        "df2.drop_duplicates(inplace=True)\n",
        "print(\"Number of rows in df2 after removing duplicates:\", df2.shape[0])\n",
        "print(\"Number of rows in df3 before removing duplicates:\", df3.shape[0])\n",
        "df3.drop_duplicates(inplace=True)\n",
        "print(\"Number of rows in df3 after removing duplicates:\", df3.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f0PHkENd3Nz_",
        "outputId": "e7a50afa-e9fe-4885-ec9f-5a78445a9332"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in df1 before removing duplicates: 891\n",
            "Number of rows in df1 after removing duplicates: 891\n",
            "Number of rows in df2 before removing duplicates: 418\n",
            "Number of rows in df2 after removing duplicates: 418\n",
            "Number of rows in df3 before removing duplicates: 418\n",
            "Number of rows in df3 after removing duplicates: 418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ðŸŒŸ Exercise 2: Handling Missing Values\n",
        "Instructions\n",
        "Identify columns in the Titanic dataset with missing values.\n",
        "Explore different strategies for handling missing data, such as removal, imputation, and filling with a constant value.\n",
        "Apply each strategy to different columns based on the nature of the data.\n",
        "Hint: Review methods like dropna(), fillna(), and SimpleImputer from scikit-learn.\n",
        "\n"
      ],
      "metadata": {
        "id": "AR9E4EsU7F7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For df1:\n",
        "# 'Age' has missing values. We can impute it with the mean or median.\n",
        "df1['Age'].fillna(df1['Age'].median(), inplace=True)\n",
        "\n",
        "# 'Cabin' has a large number of missing values. It might be best to drop this column.\n",
        "df1.drop('Cabin', axis=1, inplace=True)\n",
        "\n",
        "# 'Embarked' has a few missing values. We can fill it with the mode.\n",
        "df1['Embarked'].fillna(df1['Embarked'].mode()[0], inplace=True)\n",
        "print(\"Missing values in df1 after handling:\")\n",
        "print(df1.isnull().sum())\n",
        "\n",
        "# For df2:\n",
        "# 'Age' has missing values. Impute with median.\n",
        "df2['Age'].fillna(df2['Age'].median(), inplace=True)\n",
        "\n",
        "# 'Fare' has one missing value. Impute with median.\n",
        "df2['Fare'].fillna(df2['Fare'].median(), inplace=True)\n",
        "\n",
        "# 'Cabin' has a large number of missing values. Drop the column.\n",
        "df2.drop('Cabin', axis=1, inplace=True)\n",
        "print(\"Missing values in df2 after handling:\")\n",
        "print(df2.isnull().sum())\n",
        "\n",
        "# df3 has no missing values, so no handling is needed.\n",
        "print(\"Missing values in df3 after handling:\")\n",
        "print(df3.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HtpklRdD7Ip9",
        "outputId": "23248d32-ece9-4f6b-bd0f-f94bc758d9fe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in df1 after handling:\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n",
            "Missing values in df2 after handling:\n",
            "PassengerId    0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n",
            "Missing values in df3 after handling:\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-eef138b0b4f8>:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df1['Age'].fillna(df1['Age'].median(), inplace=True)\n",
            "<ipython-input-21-eef138b0b4f8>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df1['Embarked'].fillna(df1['Embarked'].mode()[0], inplace=True)\n",
            "<ipython-input-21-eef138b0b4f8>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df2['Age'].fillna(df2['Age'].median(), inplace=True)\n",
            "<ipython-input-21-eef138b0b4f8>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df2['Fare'].fillna(df2['Fare'].median(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŒŸ Exercise 3: Feature Engineering\n",
        "Instructions\n",
        "Create new features, such as Family Size from SibSp and Parch, and Title extracted from the Name column.\n",
        "Convert categorical variables into numerical form using techniques like one-hot encoding or label encoding.\n",
        "Normalize or standardize numerical features if required.\n",
        "Hint: Utilize Pandas for data manipulation and scikit-learnâ€™s preprocessing module for encoding.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GRrxC4CT8Cl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Family Size feature\n",
        "df1['FamilySize'] = df1['SibSp'] + df1['Parch'] + 1\n",
        "\n",
        "# Extract Title from Name\n",
        "df1['Title'] = df1['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "# Replace rare titles with a common name\n",
        "df1['Title'] = df1['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "df1['Title'] = df1['Title'].replace('Mlle', 'Miss')\n",
        "df1['Title'] = df1['Title'].replace('Ms', 'Miss')\n",
        "df1['Title'] = df1['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "# Convert categorical variables to numerical\n",
        "# 'Sex' and 'Embarked'\n",
        "df1 = pd.get_dummies(df1, columns=['Sex', 'Embarked', 'Title'], drop_first=True)\n",
        "\n",
        "# Normalize or standardize numerical features (e.g., 'Age', 'Fare', 'FamilySize')\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = ['Age', 'Fare', 'FamilySize']\n",
        "df1[numerical_cols] = scaler.fit_transform(df1[numerical_cols])\n",
        "\n",
        "print(\"\\nFeatures in df1 after engineering:\")\n",
        "print(df1.columns)\n",
        "print(\"\\nFirst 5 rows of df1 after engineering:\")\n",
        "print(df1.head())\n",
        "\n",
        "# For df2:\n",
        "# Create Family Size feature\n",
        "df2['FamilySize'] = df2['SibSp'] + df2['Parch'] + 1\n",
        "\n",
        "# Extract Title from Name\n",
        "df2['Title'] = df2['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "# Replace rare titles with a common name (using the same mapping as df1)\n",
        "df2['Title'] = df2['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "df2['Title'] = df2['Title'].replace('Mlle', 'Miss')\n",
        "df2['Title'] = df2['Title'].replace('Ms', 'Miss')\n",
        "df2['Title'] = df2['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "\n",
        "# Convert categorical variables to numerical\n",
        "# 'Sex' and 'Embarked'\n",
        "df2 = pd.get_dummies(df2, columns=['Sex', 'Embarked', 'Title'], drop_first=True)\n",
        "\n",
        "# Normalize or standardize numerical features (e.g., 'Age', 'Fare', 'FamilySize')\n",
        "# Use the same scaler fitted on df1 to avoid data leakage\n",
        "df2[numerical_cols] = scaler.transform(df2[numerical_cols])\n",
        "\n",
        "print(\"\\nFeatures in df2 after engineering:\")\n",
        "print(df2.columns)\n",
        "print(\"\\nFirst 5 rows of df2 after engineering:\")\n",
        "print(df2.head())\n",
        "\n",
        "# df3 is the submission file, typically no feature engineering is done on it directly.\n",
        "# Its 'Survived' column will be predicted using the features from df2 after training a model on df1."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Hw5p-ZMj8HQU",
        "outputId": "4c7e4472-5ab8-452c-c143-d55e7ea022c8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features in df1 after engineering:\n",
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch',\n",
            "       'Ticket', 'Fare', 'FamilySize', 'Sex_male', 'Embarked_Q', 'Embarked_S',\n",
            "       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare'],\n",
            "      dtype='object')\n",
            "\n",
            "First 5 rows of df1 after engineering:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name       Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris -0.565736      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  0.663861      1      0   \n",
            "2                             Heikkinen, Miss. Laina -0.258337      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  0.433312      1      0   \n",
            "4                           Allen, Mr. William Henry  0.433312      0      0   \n",
            "\n",
            "             Ticket      Fare  FamilySize  Sex_male  Embarked_Q  Embarked_S  \\\n",
            "0         A/5 21171 -0.502445    0.059160      True       False        True   \n",
            "1          PC 17599  0.786845    0.059160     False       False       False   \n",
            "2  STON/O2. 3101282 -0.488854   -0.560975     False       False        True   \n",
            "3            113803  0.420730    0.059160     False       False        True   \n",
            "4            373450 -0.486337   -0.560975      True       False        True   \n",
            "\n",
            "   Title_Miss  Title_Mr  Title_Mrs  Title_Rare  \n",
            "0       False      True      False       False  \n",
            "1       False     False       True       False  \n",
            "2        True     False      False       False  \n",
            "3       False     False       True       False  \n",
            "4       False      True      False       False  \n",
            "\n",
            "Features in df2 after engineering:\n",
            "Index(['PassengerId', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket',\n",
            "       'Fare', 'FamilySize', 'Sex_male', 'Embarked_Q', 'Embarked_S',\n",
            "       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare'],\n",
            "      dtype='object')\n",
            "\n",
            "First 5 rows of df2 after engineering:\n",
            "   PassengerId  Pclass                                          Name  \\\n",
            "0          892       3                              Kelly, Mr. James   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
            "2          894       2                     Myles, Mr. Thomas Francis   \n",
            "3          895       3                              Wirz, Mr. Albert   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
            "\n",
            "        Age  SibSp  Parch   Ticket      Fare  FamilySize  Sex_male  \\\n",
            "0  0.394887      0      0   330911 -0.490783   -0.560975      True   \n",
            "1  1.355510      1      0   363272 -0.507479    0.059160     False   \n",
            "2  2.508257      0      0   240276 -0.453367   -0.560975      True   \n",
            "3 -0.181487      0      0   315154 -0.474005   -0.560975      True   \n",
            "4 -0.565736      1      1  3101298 -0.401017    0.679295     False   \n",
            "\n",
            "   Embarked_Q  Embarked_S  Title_Miss  Title_Mr  Title_Mrs  Title_Rare  \n",
            "0        True       False       False      True      False       False  \n",
            "1       False        True       False     False       True       False  \n",
            "2        True       False       False      True      False       False  \n",
            "3       False        True       False      True      False       False  \n",
            "4       False        True       False     False       True       False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŒŸ Exercise 4: Outlier Detection and Handling\n",
        "Instructions\n",
        "Use statistical methods to detect outliers in columns like Fare and Age.\n",
        "Decide on a strategy to handle the identified outliers, such as capping, transformation, or removal.\n",
        "Implement the chosen strategy and assess its impact on the dataset.\n",
        "Hint: Explore methods like IQR (Interquartile Range) and Z-score for outlier detection.\n",
        "\n"
      ],
      "metadata": {
        "id": "svQK3HMX83a3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Outlier detection using IQR for 'Fare' and 'Age' in df1\n",
        "def detect_outliers_iqr(df, column):\n",
        "    q1 = df[column].quantile(0.25)\n",
        "    q3 = df[column].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - 1.5 * iqr\n",
        "    upper_bound = q3 + 1.5 * iqr\n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "    return outliers, lower_bound, upper_bound\n",
        "\n",
        "# Detect outliers in 'Fare'\n",
        "fare_outliers, fare_lower, fare_upper = detect_outliers_iqr(df1, 'Fare')\n",
        "print(f\"\\nOutliers in 'Fare' (df1) using IQR: {len(fare_outliers)} found\")\n",
        "print(f\"Fare lower bound: {fare_lower}, upper bound: {fare_upper}\")\n",
        "\n",
        "# Detect outliers in 'Age'\n",
        "age_outliers, age_lower, age_upper = detect_outliers_iqr(df1, 'Age')\n",
        "print(f\"Outliers in 'Age' (df1) using IQR: {len(age_outliers)} found\")\n",
        "print(f\"Age lower bound: {age_lower}, upper bound: {age_upper}\")\n",
        "\n",
        "# Strategy for handling outliers: Capping\n",
        "# Cap the outliers in 'Fare' and 'Age' in df1\n",
        "df1['Fare'] = np.where(df1['Fare'] > fare_upper, fare_upper,\n",
        "                       np.where(df1['Fare'] < fare_lower, fare_lower, df1['Fare']))\n",
        "\n",
        "df1['Age'] = np.where(df1['Age'] > age_upper, age_upper,\n",
        "                      np.where(df1['Age'] < age_lower, age_lower, df1['Age']))\n",
        "\n",
        "# Verify that outliers are handled by checking the new range\n",
        "print(\"\\nRange of 'Fare' in df1 after capping:\", df1['Fare'].min(), df1['Fare'].max())\n",
        "print(\"Range of 'Age' in df1 after capping:\", df1['Age'].min(), df1['Age'].max())\n",
        "\n",
        "# Visualize distributions after capping (optional)\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(x=df1['Fare'])\n",
        "plt.title('Boxplot of Fare after Capping (df1)')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(x=df1['Age'])\n",
        "plt.title('Boxplot of Age after Capping (df1)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Apply capping to df2 using the bounds calculated from df1 (to maintain consistency)\n",
        "print(\"\\nHandling outliers in df2 using bounds from df1...\")\n",
        "df2['Fare'] = np.where(df2['Fare'] > fare_upper, fare_upper,\n",
        "                       np.where(df2['Fare'] < fare_lower, fare_lower, df2['Fare']))\n",
        "\n",
        "df2['Age'] = np.where(df2['Age'] > age_upper, age_upper,\n",
        "                      np.where(df2['Age'] < age_lower, age_lower, df2['Age']))\n",
        "\n",
        "print(\"Range of 'Fare' in df2 after capping:\", df2['Fare'].min(), df2['Fare'].max())\n",
        "print(\"Range of 'Age' in df2 after capping:\", df2['Age'].min(), df2['Age'].max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "collapsed": true,
        "id": "p576XTo187nF",
        "outputId": "026a9bd3-40b5-4410-d346-243a1980edb6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Outliers in 'Fare' (df1) using IQR: 116 found\n",
            "Fare lower bound: -1.18650103391317, upper bound: 0.6731064591401562\n",
            "Outliers in 'Age' (df1) using IQR: 66 found\n",
            "Age lower bound: -2.0643084058400527, upper bound: 1.9318834468670887\n",
            "\n",
            "Range of 'Fare' in df1 after capping: -0.6484216535389205 0.6731064591401562\n",
            "Range of 'Age' in df1 after capping: -2.0643084058400527 1.9318834468670887\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Handling outliers in df2 using bounds from df1...\n",
            "Range of 'Fare' in df2 after capping: -0.6484216535389205 0.6731064591401562\n",
            "Range of 'Age' in df2 after capping: -2.0643084058400527 1.9318834468670887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Exercise 5: Data Standardization and Normalization\n",
        "Instructions\n",
        "Assess the scale and distribution of numerical columns in the dataset.\n",
        "Apply standardization to features with a wide range of values.\n",
        "Normalize data that requires a bounded range, like [0, 1].\n",
        "Hint: Consider using StandardScaler and MinMaxScaler from scikit-learnâ€™s preprocessing module.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8Z70ArUt9uEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDescription of numerical columns in df1 after feature engineering and outlier handling:\")\n",
        "print(df1[numerical_cols].describe())\n",
        "\n",
        "# Re-apply Standardization to numerical features using StandardScaler\n",
        "# We already applied StandardScaler during Feature Engineering, but let's re-emphasize the step here.\n",
        "# StandardScaler scales data to have a mean of 0 and standard deviation of 1.\n",
        "# This is suitable for features with varying ranges and distributions.\n",
        "\n",
        "# Re-instantiate scaler if needed, but using the same one fitted on df1 is correct.\n",
        "scaler = StandardScaler()\n",
        "df1[numerical_cols] = scaler.fit_transform(df1[numerical_cols])\n",
        "\n",
        "print(\"\\nDescription of numerical columns in df1 after Standardization:\")\n",
        "print(df1[numerical_cols].describe())\n",
        "\n",
        "# Apply the same Standardization to df2 using the scaler fitted on df1\n",
        "df2[numerical_cols] = scaler.transform(df2[numerical_cols])\n",
        "\n",
        "print(\"\\nDescription of numerical columns in df2 after Standardization (using scaler from df1):\")\n",
        "print(df2[numerical_cols].describe())\n",
        "\n",
        "\n",
        "# Example of Normalization (MinMaxScaler) if a bounded range like [0, 1] is required\n",
        "# Let's demonstrate on 'Fare' column, although StandardScaler might be preferred for this specific dataset.\n",
        "# MinMaxScaler scales data to a given range, typically [0, 1].\n",
        "# This can be useful for algorithms sensitive to the scale of features, especially if the features are already on a similar scale or if you need positive values.\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Create a MinMaxScaler instance\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "# Apply Min-Max Normalization to 'Fare' column in df1 as an example\n",
        "# Note: We will not keep this in the final df1 for consistency with previous steps, just demonstrating.\n",
        "df1_normalized_fare = df1.copy()\n",
        "df1_normalized_fare['Fare_Normalized'] = minmax_scaler.fit_transform(df1_normalized_fare[['Fare']])\n",
        "\n",
        "print(\"\\nDescription of 'Fare' in df1 after Min-Max Normalization (Example):\")\n",
        "print(df1_normalized_fare[['Fare', 'Fare_Normalized']].describe())\n",
        "\n",
        "# Apply the same Min-Max Normalization to df2's 'Fare' using the scaler fitted on df1\n",
        "df2_normalized_fare = df2.copy()\n",
        "df2_normalized_fare['Fare_Normalized'] = minmax_scaler.transform(df2_normalized_fare[['Fare']])\n",
        "\n",
        "print(\"\\nDescription of 'Fare' in df2 after Min-Max Normalization (Example):\")\n",
        "print(df2_normalized_fare[['Fare', 'Fare_Normalized']].describe())\n",
        "\n",
        "# For the purpose of continuing with the original dataset processing flow,\n",
        "# we will stick to the StandardScaler which was already applied.\n",
        "# The Min-Max example is just to show how it would be used.\n",
        "\n",
        "print(\"\\nFinal head of df1 after Standardization:\")\n",
        "print(df1.head())\n",
        "print(\"\\nFinal head of df2 after Standardization:\")\n",
        "print(df2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9guCVk-F90KE",
        "outputId": "9d4fc9a4-7682-40a5-ba45-9895c206c509"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Description of numerical columns in df1 after feature engineering and outlier handling:\n",
            "              Age        Fare    FamilySize\n",
            "count  891.000000  891.000000  8.910000e+02\n",
            "mean    -0.024769   -0.164247 -2.392400e-17\n",
            "std      0.927737    0.412391  1.000562e+00\n",
            "min     -2.064308   -0.648422 -5.609748e-01\n",
            "25%     -0.565736   -0.489148 -5.609748e-01\n",
            "50%     -0.104637   -0.357391 -5.609748e-01\n",
            "75%      0.433312   -0.024246  5.915988e-02\n",
            "max      1.931883    0.673106  5.640372e+00\n",
            "\n",
            "Description of numerical columns in df1 after Standardization:\n",
            "                Age          Fare    FamilySize\n",
            "count  8.910000e+02  8.910000e+02  8.910000e+02\n",
            "mean  -5.980999e-17 -1.216137e-16 -9.170866e-17\n",
            "std    1.000562e+00  1.000562e+00  1.000562e+00\n",
            "min   -2.199638e+00 -1.174727e+00 -5.609748e-01\n",
            "25%   -5.834321e-01 -7.882908e-01 -5.609748e-01\n",
            "50%   -8.613809e-02 -4.686152e-01 -5.609748e-01\n",
            "75%    4.940382e-01  3.396748e-01  5.915988e-02\n",
            "max    2.110244e+00  2.031623e+00  5.640372e+00\n",
            "\n",
            "Description of numerical columns in df2 after Standardization (using scaler from df1):\n",
            "              Age        Fare  FamilySize\n",
            "count  418.000000  418.000000  418.000000\n",
            "mean     0.021430    0.021450   -0.040240\n",
            "std      0.977861    1.019974    0.942029\n",
            "min     -2.199638   -1.174727   -0.560975\n",
            "25%     -0.500550   -0.789004   -0.560975\n",
            "50%     -0.169020   -0.468615   -0.560975\n",
            "75%      0.556200    0.362727    0.059160\n",
            "max      2.110244    2.031623    5.640372\n",
            "\n",
            "Description of 'Fare' in df1 after Min-Max Normalization (Example):\n",
            "               Fare  Fare_Normalized\n",
            "count  8.910000e+02       891.000000\n",
            "mean  -1.216137e-16         0.366375\n",
            "std    1.000562e+00         0.312056\n",
            "min   -1.174727e+00         0.000000\n",
            "25%   -7.882908e-01         0.120522\n",
            "50%   -4.686152e-01         0.220223\n",
            "75%    3.396748e-01         0.472313\n",
            "max    2.031623e+00         1.000000\n",
            "\n",
            "Description of 'Fare' in df2 after Min-Max Normalization (Example):\n",
            "             Fare  Fare_Normalized\n",
            "count  418.000000       418.000000\n",
            "mean     0.021450         0.373065\n",
            "std      1.019974         0.318111\n",
            "min     -1.174727         0.000000\n",
            "25%     -0.789004         0.120300\n",
            "50%     -0.468615         0.220223\n",
            "75%      0.362727         0.479503\n",
            "max      2.031623         1.000000\n",
            "\n",
            "Final head of df1 after Standardization:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name       Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris -0.583432      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  0.742685      1      0   \n",
            "2                             Heikkinen, Miss. Laina -0.251903      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  0.494038      1      0   \n",
            "4                           Allen, Mr. William Henry  0.494038      0      0   \n",
            "\n",
            "             Ticket      Fare  FamilySize  Sex_male  Embarked_Q  Embarked_S  \\\n",
            "0         A/5 21171 -0.820552    0.059160      True       False        True   \n",
            "1          PC 17599  2.031623    0.059160     False       False       False   \n",
            "2  STON/O2. 3101282 -0.787578   -0.560975     False       False        True   \n",
            "3            113803  1.419297    0.059160     False       False        True   \n",
            "4            373450 -0.781471   -0.560975      True       False        True   \n",
            "\n",
            "   Title_Miss  Title_Mr  Title_Mrs  Title_Rare  \n",
            "0       False      True      False       False  \n",
            "1       False     False       True       False  \n",
            "2        True     False      False       False  \n",
            "3       False     False       True       False  \n",
            "4       False      True      False       False  \n",
            "\n",
            "Final head of df2 after Standardization:\n",
            "   PassengerId  Pclass                                          Name  \\\n",
            "0          892       3                              Kelly, Mr. James   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
            "2          894       2                     Myles, Mr. Thomas Francis   \n",
            "3          895       3                              Wirz, Mr. Albert   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
            "\n",
            "        Age  SibSp  Parch   Ticket      Fare  FamilySize  Sex_male  \\\n",
            "0  0.452597      0      0   330911 -0.792258   -0.560975      True   \n",
            "1  1.488626      1      0   363272 -0.832765    0.059160     False   \n",
            "2  2.110244      0      0   240276 -0.701476   -0.560975      True   \n",
            "3 -0.169020      0      0   315154 -0.751549   -0.560975      True   \n",
            "4 -0.583432      1      1  3101298 -0.574462    0.679295     False   \n",
            "\n",
            "   Embarked_Q  Embarked_S  Title_Miss  Title_Mr  Title_Mrs  Title_Rare  \n",
            "0        True       False       False      True      False       False  \n",
            "1       False        True       False     False       True       False  \n",
            "2        True       False       False      True      False       False  \n",
            "3       False        True       False      True      False       False  \n",
            "4       False        True       False     False       True       False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Exercise 6: Feature Encoding\n",
        "Instructions\n",
        "Identify categorical columns in the Titanic dataset, such as Sex and Embarked.\n",
        "Use one-hot encoding for nominal variables and label encoding for ordinal variables.\n",
        "Integrate the encoded features back into the main dataset.\n",
        "Hint: Utilize pandas.get_dummies() for one-hot encoding and LabelEncoder from scikit-learn for label encoding.\n",
        "\n"
      ],
      "metadata": {
        "id": "6M0y2ZGo-Zje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-identifying categorical columns for clarity\n",
        "# Based on previous steps, 'Sex', 'Embarked', and 'Title' were identified and one-hot encoded.\n",
        "# We will reiterate the process here as per the exercise instructions,\n",
        "# ensuring the code is runnable independently based on the state of df1 and df2 at the beginning of Exercise 6.\n",
        "\n",
        "# We can confirm the current columns in df1 and df2.\n",
        "print(\"\\nFinal columns in df1 after all previous steps:\")\n",
        "print(df1.columns.tolist())\n",
        "print(\"\\nFinal columns in df2 after all previous steps:\")\n",
        "print(df2.columns.tolist())\n",
        "\n",
        "# Re-identifying categorical columns that WERE encoded for clarity from previous steps\n",
        "encoded_nominal_cols_df1 = ['Sex_male', 'Embarked_Q', 'Embarked_S', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare']\n",
        "# Check which of these columns actually exist in df1 (some categories might not be present in train/test)\n",
        "existing_encoded_cols_df1 = [col for col in encoded_nominal_cols_df1 if col in df1.columns]\n",
        "print(f\"\\nNominal features one-hot encoded in df1: {existing_encoded_cols_df1}\")\n",
        "print(\"\\n'Pclass' is numeric (1, 2, 3) and treated as ordinal.\")\n",
        "print(\"It was standardized in Exercise 5 and is present in the final columns.\")\n",
        "\n",
        "# Display the head of the dataframes to show the result of previous processing.\n",
        "print(\"\\nFirst 5 rows of df1 after all processing (including encoding and standardization):\")\n",
        "print(df1.head())\n",
        "print(\"\\nFirst 5 rows of df2 after all processing (including encoding and standardization):\")\n",
        "print(df2.head())\n",
        "\n",
        "# Let's check the data types and unique values to confirm\n",
        "print(\"\\nData types in df1 before encoding:\")\n",
        "print(df1.dtypes)\n",
        "\n",
        "\n",
        "print(\"Unique values in 'Pclass' (df1):\", df1['Pclass'].unique())\n",
        "\n",
        "# One-Hot Encoding for Nominal Variables ('Sex', 'Embarked', 'Title')\n",
        "# Use pandas.get_dummies. drop_first=True is used to avoid multicollinearity.\n",
        "# We already did this in Exercise 3, but let's repeat the step here for self-containment of Exercise 6.\n",
        "# It's important to make sure the columns exist before encoding.\n",
        "# If the columns were already encoded in prior steps, this step might be redundant or require dropping existing dummy columns first.\n",
        "# Assuming we are continuing from Exercise 5 where numerical features were standardized,\n",
        "# the categorical columns ('Sex', 'Embarked', 'Title') should already be one-hot encoded from Exercise 3.\n",
        "\n",
        "# Let's confirm if the dummy columns already exist.\n",
        "# Expected columns after one-hot encoding Sex, Embarked, Title (drop_first=True):\n",
        "# 'Sex_male', 'Embarked_Q', 'Embarked_S', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare'\n",
        "\n",
        "encoded_cols = ['Sex_male', 'Embarked_Q', 'Embarked_S', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare']\n",
        "cols_to_encode = ['Sex', 'Embarked', 'Title']\n",
        "\n",
        "# Check if original columns still exist or if dummy columns are already present\n",
        "if all(col in df1.columns for col in cols_to_encode):\n",
        "    print(\"\\nPerforming One-Hot Encoding for 'Sex', 'Embarked', 'Title'...\")\n",
        "    # Drop original columns if they still exist and then encode\n",
        "    df1 = df1.drop(columns=cols_to_encode, errors='ignore')\n",
        "    df1 = pd.get_dummies(df1, columns=cols_to_encode, drop_first=True)\n",
        "    # Ensure consistent columns between train and test after encoding\n",
        "    # This is a crucial step in real-world scenarios.\n",
        "    # Let's re-apply encoding to df2 as well.\n",
        "    df2 = df2.drop(columns=cols_to_encode, errors='ignore')\n",
        "    df2 = pd.get_dummies(df2, columns=cols_to_encode, drop_first=True)\n",
        "\n",
        "    # Align columns - add missing columns (with 0) and drop extra columns\n",
        "    # This step is vital if one dataset (e.g., test) is missing a category present in the other (e.g., train)\n",
        "    train_cols = df1.columns\n",
        "    test_cols = df2.columns\n",
        "\n",
        "    missing_in_test = set(train_cols) - set(test_cols)\n",
        "    for c in missing_in_test:\n",
        "        df2[c] = 0\n",
        "\n",
        "    missing_in_train = set(test_cols) - set(train_cols)\n",
        "    for c in missing_in_train:\n",
        "        df1[c] = 0\n",
        "\n",
        "    # Ensure the order of columns is the same\n",
        "    df2 = df2[train_cols]\n",
        "\n",
        "    print(\"\\nColumns in df1 after One-Hot Encoding and alignment:\")\n",
        "    print(df1.columns)\n",
        "    print(\"\\nColumns in df2 after One-Hot Encoding and alignment:\")\n",
        "    print(df2.columns)\n",
        "\n",
        "elif any(col in df1.columns for col in encoded_cols):\n",
        "    print(\"\\n'Sex', 'Embarked', 'Title' appear to be already One-Hot Encoded.\")\n",
        "    # If already encoded, skip get_dummies but maybe check for alignment if needed.\n",
        "    # Assuming they were encoded and aligned correctly in Exercise 3.\n",
        "else:\n",
        "     print(\"\\nCategorical columns ('Sex', 'Embarked', 'Title') not found in expected formats for encoding.\")\n",
        "     # Handle error or adjust logic based on actual column names\n",
        "\n",
        "# Label Encoding for Ordinal Variables ('Pclass')\n",
        "# 'Pclass' is 1st, 2nd, 3rd class, which is ordinal. Label encoding is suitable.\n",
        "# However, since Pclass values are already 1, 2, 3, they can often be used directly\n",
        "# as they represent order. If they were non-numeric labels (e.g., 'First', 'Second', 'Third'),\n",
        "# LabelEncoder would be necessary.\n",
        "# Since they are already numeric and ordinal, we can potentially leave them as is.\n",
        "# If using a model sensitive to scale, they might also be standardized, which we already did for numerical features.\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Example of Label Encoding if Pclass needed it (not strictly necessary here as it's already 1,2,3)\n",
        "# Let's pretend Pclass was ['First', 'Second', 'Third'] for demonstration.\n",
        "# If df1['Pclass'] had string values:\n",
        "# le = LabelEncoder()\n",
        "# df1['Pclass_Encoded'] = le.fit_transform(df1['Pclass'])\n",
        "# df2['Pclass_Encoded'] = le.transform(df2['Pclass'])\n",
        "# df1 = df1.drop('Pclass', axis=1)\n",
        "# df2 = df2.drop('Pclass', axis=1)\n",
        "\n",
        "print(\"\\n'Pclass' is already numeric (1, 2, 3) and represents ordinal categories.\")\n",
        "print(\"No explicit Label Encoding applied as it's already in a suitable format.\")\n",
        "print(\"Pclass was included in the numerical features standardization in Exercise 5.\")\n",
        "\n",
        "\n",
        "print(\"\\nFirst 5 rows of df1 after Feature Encoding:\")\n",
        "print(df1.head())\n",
        "print(\"\\nFirst 5 rows of df2 after Feature Encoding:\")\n",
        "print(df2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XpF6Al8F-c4t",
        "outputId": "6b014df5-80cd-4dd1-b348-df3605df49d7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final columns in df1 after all previous steps:\n",
            "['PassengerId', 'Survived', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'FamilySize', 'Sex_male', 'Embarked_Q', 'Embarked_S', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare']\n",
            "\n",
            "Final columns in df2 after all previous steps:\n",
            "['PassengerId', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'FamilySize', 'Sex_male', 'Embarked_Q', 'Embarked_S', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare']\n",
            "\n",
            "Nominal features one-hot encoded in df1: ['Sex_male', 'Embarked_Q', 'Embarked_S', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare']\n",
            "\n",
            "'Pclass' is numeric (1, 2, 3) and treated as ordinal.\n",
            "It was standardized in Exercise 5 and is present in the final columns.\n",
            "\n",
            "First 5 rows of df1 after all processing (including encoding and standardization):\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name       Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris -0.583432      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  0.742685      1      0   \n",
            "2                             Heikkinen, Miss. Laina -0.251903      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  0.494038      1      0   \n",
            "4                           Allen, Mr. William Henry  0.494038      0      0   \n",
            "\n",
            "             Ticket      Fare  FamilySize  Sex_male  Embarked_Q  Embarked_S  \\\n",
            "0         A/5 21171 -0.820552    0.059160      True       False        True   \n",
            "1          PC 17599  2.031623    0.059160     False       False       False   \n",
            "2  STON/O2. 3101282 -0.787578   -0.560975     False       False        True   \n",
            "3            113803  1.419297    0.059160     False       False        True   \n",
            "4            373450 -0.781471   -0.560975      True       False        True   \n",
            "\n",
            "   Title_Miss  Title_Mr  Title_Mrs  Title_Rare  \n",
            "0       False      True      False       False  \n",
            "1       False     False       True       False  \n",
            "2        True     False      False       False  \n",
            "3       False     False       True       False  \n",
            "4       False      True      False       False  \n",
            "\n",
            "First 5 rows of df2 after all processing (including encoding and standardization):\n",
            "   PassengerId  Pclass                                          Name  \\\n",
            "0          892       3                              Kelly, Mr. James   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
            "2          894       2                     Myles, Mr. Thomas Francis   \n",
            "3          895       3                              Wirz, Mr. Albert   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
            "\n",
            "        Age  SibSp  Parch   Ticket      Fare  FamilySize  Sex_male  \\\n",
            "0  0.452597      0      0   330911 -0.792258   -0.560975      True   \n",
            "1  1.488626      1      0   363272 -0.832765    0.059160     False   \n",
            "2  2.110244      0      0   240276 -0.701476   -0.560975      True   \n",
            "3 -0.169020      0      0   315154 -0.751549   -0.560975      True   \n",
            "4 -0.583432      1      1  3101298 -0.574462    0.679295     False   \n",
            "\n",
            "   Embarked_Q  Embarked_S  Title_Miss  Title_Mr  Title_Mrs  Title_Rare  \n",
            "0        True       False       False      True      False       False  \n",
            "1       False        True       False     False       True       False  \n",
            "2        True       False       False      True      False       False  \n",
            "3       False        True       False      True      False       False  \n",
            "4       False        True       False     False       True       False  \n",
            "\n",
            "Data types in df1 before encoding:\n",
            "PassengerId      int64\n",
            "Survived         int64\n",
            "Pclass           int64\n",
            "Name            object\n",
            "Age            float64\n",
            "SibSp            int64\n",
            "Parch            int64\n",
            "Ticket          object\n",
            "Fare           float64\n",
            "FamilySize     float64\n",
            "Sex_male          bool\n",
            "Embarked_Q        bool\n",
            "Embarked_S        bool\n",
            "Title_Miss        bool\n",
            "Title_Mr          bool\n",
            "Title_Mrs         bool\n",
            "Title_Rare        bool\n",
            "dtype: object\n",
            "Unique values in 'Pclass' (df1): [3 1 2]\n",
            "\n",
            "'Sex', 'Embarked', 'Title' appear to be already One-Hot Encoded.\n",
            "\n",
            "'Pclass' is already numeric (1, 2, 3) and represents ordinal categories.\n",
            "No explicit Label Encoding applied as it's already in a suitable format.\n",
            "Pclass was included in the numerical features standardization in Exercise 5.\n",
            "\n",
            "First 5 rows of df1 after Feature Encoding:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name       Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris -0.583432      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  0.742685      1      0   \n",
            "2                             Heikkinen, Miss. Laina -0.251903      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  0.494038      1      0   \n",
            "4                           Allen, Mr. William Henry  0.494038      0      0   \n",
            "\n",
            "             Ticket      Fare  FamilySize  Sex_male  Embarked_Q  Embarked_S  \\\n",
            "0         A/5 21171 -0.820552    0.059160      True       False        True   \n",
            "1          PC 17599  2.031623    0.059160     False       False       False   \n",
            "2  STON/O2. 3101282 -0.787578   -0.560975     False       False        True   \n",
            "3            113803  1.419297    0.059160     False       False        True   \n",
            "4            373450 -0.781471   -0.560975      True       False        True   \n",
            "\n",
            "   Title_Miss  Title_Mr  Title_Mrs  Title_Rare  \n",
            "0       False      True      False       False  \n",
            "1       False     False       True       False  \n",
            "2        True     False      False       False  \n",
            "3       False     False       True       False  \n",
            "4       False      True      False       False  \n",
            "\n",
            "First 5 rows of df2 after Feature Encoding:\n",
            "   PassengerId  Pclass                                          Name  \\\n",
            "0          892       3                              Kelly, Mr. James   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
            "2          894       2                     Myles, Mr. Thomas Francis   \n",
            "3          895       3                              Wirz, Mr. Albert   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
            "\n",
            "        Age  SibSp  Parch   Ticket      Fare  FamilySize  Sex_male  \\\n",
            "0  0.452597      0      0   330911 -0.792258   -0.560975      True   \n",
            "1  1.488626      1      0   363272 -0.832765    0.059160     False   \n",
            "2  2.110244      0      0   240276 -0.701476   -0.560975      True   \n",
            "3 -0.169020      0      0   315154 -0.751549   -0.560975      True   \n",
            "4 -0.583432      1      1  3101298 -0.574462    0.679295     False   \n",
            "\n",
            "   Embarked_Q  Embarked_S  Title_Miss  Title_Mr  Title_Mrs  Title_Rare  \n",
            "0        True       False       False      True      False       False  \n",
            "1       False        True       False     False       True       False  \n",
            "2        True       False       False      True      False       False  \n",
            "3       False        True       False      True      False       False  \n",
            "4       False        True       False     False       True       False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ðŸŒŸ Exercise 7: Data Transformation for Age Feature\n",
        "Instructions\n",
        "Create age groups (bins) from the Age column to categorize passengers into different age categories.\n",
        "Apply one-hot encoding to the age groups to convert them into binary features.\n",
        "Hint: Use pd.cut() for binning the Age column and pd.get_dummies() for one-hot encoding.\n",
        "\n"
      ],
      "metadata": {
        "id": "quN4BZ35ALcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create age bins\n",
        "# Define the bins and labels\n",
        "bins = [0, 12, 18, 35, 60, 100] # Example bins: Child, Teenager, Young Adult, Adult, Senior\n",
        "labels = ['Child', 'Teenager', 'YoungAdult', 'Adult', 'Senior']\n",
        "\n",
        "# Apply binning to df1\n",
        "# Use include_lowest=True to include the minimum value in the first bin\n",
        "df1['AgeGroup'] = pd.cut(df1['Age'], bins=bins, labels=labels, right=True, include_lowest=True)\n",
        "\n",
        "# Apply binning to df2 using the same bins and labels\n",
        "df2['AgeGroup'] = pd.cut(df2['Age'], bins=bins, labels=labels, right=True, include_lowest=True)\n",
        "\n",
        "print(\"\\nValue counts for 'AgeGroup' in df1:\")\n",
        "print(df1['AgeGroup'].value_counts())\n",
        "print(\"\\nValue counts for 'AgeGroup' in df2:\")\n",
        "print(df2['AgeGroup'].value_counts())\n",
        "\n",
        "# Apply one-hot encoding to the 'AgeGroup' column\n",
        "# Use get_dummies and drop_first=True\n",
        "df1 = pd.get_dummies(df1, columns=['AgeGroup'], prefix='AgeGroup', drop_first=True)\n",
        "df2 = pd.get_dummies(df2, columns=['AgeGroup'], prefix='AgeGroup', drop_first=True)\n",
        "\n",
        "# Align columns between df1 and df2 after encoding\n",
        "train_cols = df1.columns\n",
        "test_cols = df2.columns\n",
        "\n",
        "missing_in_test = set(train_cols) - set(test_cols)\n",
        "for c in missing_in_test:\n",
        "    df2[c] = 0\n",
        "\n",
        "missing_in_train = set(test_cols) - set(train_cols)\n",
        "for c in missing_in_train:\n",
        "    df1[c] = 0\n",
        "\n",
        "# Ensure the order of columns is the same\n",
        "df2 = df2[train_cols]\n",
        "\n",
        "\n",
        "print(\"\\nFeatures in df1 after Age Group encoding:\")\n",
        "print(df1.columns.tolist())\n",
        "print(\"\\nFeatures in df2 after Age Group encoding:\")\n",
        "print(df2.columns.tolist())\n",
        "\n",
        "print(\"\\nFirst 5 rows of df1 after Age Group encoding:\")\n",
        "print(df1.head())\n",
        "print(\"\\nFirst 5 rows of df2 after Age Group encoding:\")\n",
        "print(df2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHdWoYhzAP9g",
        "outputId": "88ccf101-7929-401a-ff33-1d68000a8739"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Value counts for 'AgeGroup' in df1:\n",
            "AgeGroup\n",
            "Child         330\n",
            "Teenager        0\n",
            "YoungAdult      0\n",
            "Adult           0\n",
            "Senior          0\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Value counts for 'AgeGroup' in df2:\n",
            "AgeGroup\n",
            "Child         147\n",
            "Teenager        0\n",
            "YoungAdult      0\n",
            "Adult           0\n",
            "Senior          0\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Features in df1 after Age Group encoding:\n",
            "['PassengerId', 'Survived', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'FamilySize', 'Sex_male', 'Embarked_Q', 'Embarked_S', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare', 'AgeGroup_Teenager', 'AgeGroup_YoungAdult', 'AgeGroup_Adult', 'AgeGroup_Senior']\n",
            "\n",
            "Features in df2 after Age Group encoding:\n",
            "['PassengerId', 'Survived', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'FamilySize', 'Sex_male', 'Embarked_Q', 'Embarked_S', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare', 'AgeGroup_Teenager', 'AgeGroup_YoungAdult', 'AgeGroup_Adult', 'AgeGroup_Senior']\n",
            "\n",
            "First 5 rows of df1 after Age Group encoding:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name       Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris -0.583432      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  0.742685      1      0   \n",
            "2                             Heikkinen, Miss. Laina -0.251903      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  0.494038      1      0   \n",
            "4                           Allen, Mr. William Henry  0.494038      0      0   \n",
            "\n",
            "             Ticket      Fare  FamilySize  ...  Embarked_Q  Embarked_S  \\\n",
            "0         A/5 21171 -0.820552    0.059160  ...       False        True   \n",
            "1          PC 17599  2.031623    0.059160  ...       False       False   \n",
            "2  STON/O2. 3101282 -0.787578   -0.560975  ...       False        True   \n",
            "3            113803  1.419297    0.059160  ...       False        True   \n",
            "4            373450 -0.781471   -0.560975  ...       False        True   \n",
            "\n",
            "   Title_Miss  Title_Mr  Title_Mrs  Title_Rare  AgeGroup_Teenager  \\\n",
            "0       False      True      False       False              False   \n",
            "1       False     False       True       False              False   \n",
            "2        True     False      False       False              False   \n",
            "3       False     False       True       False              False   \n",
            "4       False      True      False       False              False   \n",
            "\n",
            "   AgeGroup_YoungAdult  AgeGroup_Adult  AgeGroup_Senior  \n",
            "0                False           False            False  \n",
            "1                False           False            False  \n",
            "2                False           False            False  \n",
            "3                False           False            False  \n",
            "4                False           False            False  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "First 5 rows of df2 after Age Group encoding:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         0       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         0       3   \n",
            "\n",
            "                                           Name       Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James  0.452597      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  1.488626      1      0   \n",
            "2                     Myles, Mr. Thomas Francis  2.110244      0      0   \n",
            "3                              Wirz, Mr. Albert -0.169020      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist) -0.583432      1      1   \n",
            "\n",
            "    Ticket      Fare  FamilySize  ...  Embarked_Q  Embarked_S  Title_Miss  \\\n",
            "0   330911 -0.792258   -0.560975  ...        True       False       False   \n",
            "1   363272 -0.832765    0.059160  ...       False        True       False   \n",
            "2   240276 -0.701476   -0.560975  ...        True       False       False   \n",
            "3   315154 -0.751549   -0.560975  ...       False        True       False   \n",
            "4  3101298 -0.574462    0.679295  ...       False        True       False   \n",
            "\n",
            "   Title_Mr  Title_Mrs  Title_Rare  AgeGroup_Teenager  AgeGroup_YoungAdult  \\\n",
            "0      True      False       False              False                False   \n",
            "1     False       True       False              False                False   \n",
            "2      True      False       False              False                False   \n",
            "3      True      False       False              False                False   \n",
            "4     False       True       False              False                False   \n",
            "\n",
            "   AgeGroup_Adult  AgeGroup_Senior  \n",
            "0           False            False  \n",
            "1           False            False  \n",
            "2           False            False  \n",
            "3           False            False  \n",
            "4           False            False  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    }
  ]
}