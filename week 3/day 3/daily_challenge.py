# -*- coding: utf-8 -*-
"""daily challenge

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16JpAoZoqWQuIfztv74_UeM5V8YpFuU9B

Your Task
Download and import the Data Science Job Salary dataset.
Normalize the ‘salary’ column using Min-Max normalization which scales all salary values between 0 and 1.
Implement dimensionality reduction like Principal Component Analysis (PCA) or t-SNE to reduce the number of features (columns) in the dataset.
Group the dataset by the ‘experience_level’ column and calculate the average and median salary for each experience level (e.g., Junior, Mid-level, Senior).
Hint :
As a reminder, normalization is crucial when dealing with data that has different ranges. For example, salary data might have a wide range (e.g., from $20,000 to $200,000). By scaling the data using Min-Max normalization, you make sure that all salary values fall within a consistent range (0 to 1). This is particularly helpful when the data is going to be used in machine learning models, as some algorithms (like k-nearest neighbors or neural networks) perform better when features are normalized. It ensures that no single salary dominates the learning process, making the analysis more balanced.

Dimensionality reduction helps simplify complex datasets by reducing the number of variables under consideration. This can make the data more manageable and help avoid the curse of dimensionality—a phenomenon where machine learning models struggle when dealing with high-dimensional data.
PCA, for instance, helps in retaining the most important information (variance) from the dataset while reducing noise and redundancy.
It can also speed up the training process for models and help in visualizing data in fewer dimensions.

Aggregating data helps in understanding trends within subgroups of the dataset.
Calculating average and median salaries for each experience level gives insights into the compensation distribution and disparities across different job levels. This kind of aggregation can help in answering business questions like “How does salary evolve with experience?” or “What is the salary distribution for senior-l
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

!wget -O ds_salaries.csv https://raw.githubusercontent.com/PlayingNumbers/ds_salary_proj/main/glassdoor_jobs.csv

# Load the dataset
try:
  df = pd.read_csv('ds_salaries.csv')
except FileNotFoundError:
  print("Error: 'ds_salaries.csv' not found. Please make sure the file is in the current directory or provide the correct path.")
  exit()

# Normalize the 'salary' column
scaler = MinMaxScaler()
df['salary_normalized'] = scaler.fit_transform(df[['Salary']])


# Handle non-numeric columns for PCA (e.g., one-hot encode categorical features)
# Select relevant numeric columns for PCA
numeric_cols = df.select_dtypes(include=['number']).columns
numeric_df = df[numeric_cols]

# Apply PCA
pca = PCA(n_components=2) # Reduce to 2 components for visualization
df_pca = pca.fit_transform(numeric_df)
# Create a DataFrame for the reduced data
df_pca = pd.DataFrame(data=df_pca, columns=['PC1', 'PC2'])
df = pd.concat([df, df_pca], axis=1)

# Group by 'experience_level' and calculate average and median salary
salary_stats = df.groupby('experience_level')['salary_normalized'].agg(['mean', 'median'])
salary_stats