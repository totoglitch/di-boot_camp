# -*- coding: utf-8 -*-
"""xp

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TH_werjI9PPdZtwuNCnEhXq6JeoZItLQ

Exercise 1: Introduction to Data Analysis (Easy)


Objective: Understand the basic overview and significance of data analysis.
Task:
Write a short essay or report on the following topics:

What is data analysis?
Why is data analysis important in modern contexts?
List and describe three areas where data analysis is applied today.
Hint/Tip:

Research current trends in data analysis and real-world examples to provide depth to your essay.
"""

# prompt: write a short essay on the following topics : what is data analysis and why is it important list and describe three areas where it is applied

# What is data analysis?
# Data analysis is the process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making.  It involves applying various techniques to extract meaningful insights from raw data, which can be structured (e.g., databases) or unstructured (e.g., text, images).  This process can range from simple descriptive statistics to complex machine learning algorithms, depending on the goals of the analysis and the nature of the data.


# Why is data analysis important in modern contexts?
# In today's data-driven world, data analysis plays a crucial role across numerous sectors.  Organizations use data analysis to understand customer behavior, optimize operations, identify trends, and predict future outcomes.  It empowers businesses to make informed decisions, improve efficiency, personalize customer experiences, and gain a competitive advantage.  For example, understanding customer purchasing patterns through analysis allows businesses to tailor marketing campaigns and product development strategies more effectively.  Moreover, in scientific research, data analysis is paramount for validating hypotheses, discovering new patterns, and advancing our understanding of the world. Data analysis helps navigate uncertainty and make better decisions based on objective evidence rather than intuition or guesswork.


# Three areas where data analysis is applied today:
# 1. Business Intelligence and Marketing: Businesses leverage data analysis to understand customer preferences, market trends, and sales performance.  Analyzing website traffic, social media interactions, and sales data helps companies personalize marketing campaigns, target specific demographics, and optimize pricing strategies. For instance, A/B testing, a common data analysis technique, is used to compare different versions of a website or advertisement to determine which performs better.  Customer relationship management (CRM) systems heavily rely on data analysis to segment customers, forecast demand, and enhance customer satisfaction.
#
# 2. Healthcare and Medicine: Data analysis plays an increasingly important role in healthcare.  Analyzing patient data, medical images, and clinical trial results can lead to early disease diagnosis, personalized treatment plans, and improved patient outcomes.  For example, machine learning algorithms are being used to analyze medical images to detect tumors or anomalies more accurately and efficiently than human review alone.  Analyzing large datasets of patient records can also help identify risk factors for certain diseases and develop more effective preventative measures.
#
# 3. Finance and Economics: In finance, data analysis is used for risk assessment, fraud detection, algorithmic trading, and portfolio optimization.  Analyzing financial markets, transaction data, and economic indicators helps investors and financial institutions make informed investment decisions and manage risk effectively.  For example, analyzing historical stock prices and economic indicators can be used to develop predictive models for future market trends.  Similarly, credit scoring models are based on data analysis techniques to assess the creditworthiness of borrowers and minimize the risk of default.

"""Exercise 2: Dataset Loading and Initial Analysis


Objective: Practice dataset loading from Kaggle and initial analysis.
Task:
for the following dataset : How Much Sleep Do Americans Really Get?, Global Trends in Mental Health Disorder and Credit Card Approvals.

Load the dataset into Jupyter or Google Colab.
Display the first few rows.
Provide a brief dataset description.

"""

# prompt: upload a dataset from kaggle about credit card approvals and display the first few rows and provide a brief dataset description

import pandas as pd
!pip install opendatasets
import opendatasets as od

# Download the dataset (replace with the actual Kaggle dataset URL)
dataset_url = 'https://www.kaggle.com/datasets/rikdifos/credit-card-approval-prediction'
od.download(dataset_url)

# Assuming the dataset is in a CSV file named 'application_record.csv'
file_path = 'credit-card-approval-prediction/application_record.csv'  # Replace if needed

try:
    # Load the dataset into a Pandas DataFrame
    df = pd.read_csv(file_path)

    # Display the first few rows
    print(df.head())

    # Provide a brief dataset description
    print("\nDataset Description:")
    print(df.info())  # Get basic information about the dataset
    print("\nDescriptive Statistics:\n", df.describe())  # Get descriptive statistics


except FileNotFoundError:
    print(f"Error: File not found at {file_path}. Please check the file path.")
except pd.errors.ParserError:
    print(f"Error: Could not parse the file at {file_path}. Please check the file format.")
except Exception as e:
    print(f"An unexpected error occurred: {e}")

"""Exercise 3: Identifying Data Types


Objective: Learn to identify different data types.
Task:
For the datasets from the previous exercise, categorize each column of it as either quantitative or qualitative and explain your reasoning.


"""

import pandas as pd

# Assuming 'df' is already loaded from the previous code block
# If not, load it here:
# file_path = 'credit-card-approval-prediction/application_record.csv'
# df = pd.read_csv(file_path)

def categorize_columns(df):
  """Categorizes columns of a Pandas DataFrame as quantitative or qualitative."""

  qualitative_cols = []
  quantitative_cols = []
  for col in df.columns:
    if pd.api.types.is_numeric_dtype(df[col]):
        quantitative_cols.append(col)
    else:
        qualitative_cols.append(col)

  print("Qualitative Columns:")
  for col in qualitative_cols:
    print(f"- {col}: {df[col].dtype} - likely categorical or textual data.")

  print("\nQuantitative Columns:")
  for col in quantitative_cols:
    print(f"- {col}: {df[col].dtype} - likely numerical data.")

categorize_columns(df)

"""Exercise 4: Exploring Data Types


Objective: Learn about different types of data in data analysis.
Task:
Load the Iris dataset using Kaggle into a Jupyter Notebook or Google Colaboratory Notebook.
Identify and list which columns in your dataset are qualitative and which are quantitative.
Write a brief description of why each column is classified as qualitative or quantitative.
Tools: Jupyter Notebook, Python with Pandas library.


"""

import pandas as pd
import opendatasets as od

dataset_url = 'https://www.kaggle.com/datasets/uciml/iris'
od.download(dataset_url)

file_path = 'iris/Iris.csv'
df_iris = pd.read_csv(file_path)

def categorize_iris_columns(df):
    """Categorizes columns of the Iris dataset."""
    qualitative_cols = []
    quantitative_cols = []

    for col in df.columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            quantitative_cols.append(col)
        else:
            qualitative_cols.append(col)

    print("Qualitative Columns:")
    for col in qualitative_cols:
        print(f"- {col}: {df[col].dtype} - likely categorical data (species of Iris).")

    print("\nQuantitative Columns:")
    for col in quantitative_cols:
      print(f"- {col}: {df[col].dtype} - likely numerical measurements (sepal length, sepal width, petal length, petal width).")

categorize_iris_columns(df_iris)

"""Exercise 5: Basic Data Analysis with Google Colab


Objective: Perform basic data analysis using Google Colab.
Task:
Using the same notebook from the previous exercise, perform basic data analysis tasks:
Calculate the mean, median, and mode of a quantitative column.
Create a simple plot (like a histogram or bar chart) to visualize the data using Matplotlib/Seaborn libraries :
import matplotlib.pyplot as plt
plt.plot(data['Name_column1'], data['Name_column2'])
plt.show()
Document your findings in the notebook.
Tools: Google Colab, Python with Pandas and Matplotlib/Seaborn libraries.


"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Assuming 'df_iris' is already loaded from the previous code block


print(f"Mean Sepal Length: {mean_sepal_length}")
print(f"Median Sepal Length: {median_sepal_length}")
print(f"Mode Sepal Length: {mode_sepal_length}")

# Create a histogram of 'SepalLengthCm'
plt.figure(figsize=(8, 6))
sns.histplot(df_iris['SepalLengthCm'], kde=True)
plt.title('Distribution of Sepal Length')
plt.xlabel('Sepal Length (cm)')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(8, 6))
sns.boxplot(x='Species', y='SepalLengthCm', data=df_iris)
plt.title('Sepal Length Distribution by Species')
plt.xlabel('Species')
plt.ylabel('Sepal Length (cm)')
plt.show()

"""Exercise 6: Basic Observation Skills in Data Analysis


Objective: Develop observation skills for data analysis.
Task:
Load the How Much Sleep Do Americans Really Get? dataset into Jupyter or Google Colab.
Identify columns that could be interesting for a specific type of analysis (e.g., trend analysis, group comparison) and explain your choice.
Tools: Jupyter Notebook, Python with Pandas library.

"""

import pandas as pd
!pip install opendatasets
import opendatasets as od

dataset_url = 'https://www.kaggle.com/datasets/cdc/2019-national-health-interview-survey'
od.download(dataset_url)

file_path = '2019-national-health-interview-survey/2019.csv'

try:
    df_sleep = pd.read_csv(file_path, low_memory=False)


    print(df_sleep.head())

    # Get information about the columns
    print(df_sleep.info())

    # Example: Identify interesting columns for trend analysis related to sleep duration and age
    interesting_columns = ['_AGE_G', 'SLEEP']

    print("\nInteresting columns for trend analysis (sleep duration vs. age):")
    for col in interesting_columns:
        print(f"- {col}: {df_sleep[col].dtype} - {df_sleep[col].describe()}")  # Basic stats for selected columns

except FileNotFoundError:
    print(f"Error: File not found at {file_path}. Please check the file path.")
except pd.errors.ParserError:
    print(f"Error: Could not parse the file at {file_path}. Please check the file format.")
except Exception as e:
    print(f"An unexpected error occurred: {e}")