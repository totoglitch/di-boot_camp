# -*- coding: utf-8 -*-
"""xp

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pOaAjOoI6Uc8UoR8zxA6rFQsk2ncPYN2

ðŸŒŸ Exercise 1: Identifying Data Types
Below are various data sources. Identify whether each one is an example of structured or unstructured data.

A companyâ€™s financial reports stored in an Excel file.
Photographs uploaded to a social media platform.
A collection of news articles on a website.
Inventory data in a relational database.
Recorded interviews from a market research study.
"""

# prompt: identifying data types

# Identifying Data Types

# A companyâ€™s financial reports stored in an Excel file.  -> Structured
# Photographs uploaded to a social media platform. -> Unstructured
# A collection of news articles on a website. -> Unstructured
# Inventory data in a relational database. -> Structured
# Recorded interviews from a market research study. -> Unstructured

"""Exercise 2: Transformation Exercise
For each of the following unstructured data sources, propose a method to convert it into structured data. Explain your reasoning.

A series of blog posts about travel experiences.
Audio recordings of customer service calls.
Handwritten notes from a brainstorming session.
A video tutorial on cooking.

"""

# A series of blog posts about travel experiences.
# Method: Natural Language Processing (NLP) and topic modeling.
# Reasoning: NLP techniques can be used to extract key entities (locations, dates, activities), sentiments, and topics from the text.
#            Topic modeling algorithms can group similar blog posts together, revealing recurring themes and patterns.
#            This information can be organized into a structured database with columns for location, date, activity, sentiment, and topic.

# Audio recordings of customer service calls.
# Method: Speech-to-text conversion, followed by NLP and sentiment analysis.
# Reasoning: First, convert audio to text using an accurate speech-to-text engine.
#            Then, employ NLP techniques to identify customer issues, agent responses, and key phrases.
#            Sentiment analysis can determine the emotional tone of the conversation (positive, negative, neutral).
#            Store the extracted information, along with timestamps and call IDs, in a structured database.

# Handwritten notes from a brainstorming session.
# Method: Optical Character Recognition (OCR), followed by NLP and keyword extraction.
# Reasoning: OCR will convert handwritten text to digital text.  NLP techniques can then identify key concepts, ideas, and action items.
#            Keyword extraction will help categorize the notes and highlight important topics. The structured data can include timestamps, author of the note,
#            and a list of keywords extracted from the notes.

# A video tutorial on cooking.
# Method: Video transcription (speech-to-text), object recognition, and timestamping.
# Reasoning: Convert the audio portion of the video to text using a speech-to-text engine.
#            Use object recognition to identify ingredients and cooking utensils shown in the video, along with their timestamps.
#            The structured data could include a list of ingredients, steps in the recipe, timestamps for each step,  and corresponding images/objects identified.

"""ðŸŒŸ Exercise 3 : Import a file from Kaggle
Import the train dataset. Use the train.csv file.
Print the first few rows of the DataFrame.

"""

import pandas as pd

!pip install kaggle
!mkdir ~/.kaggle
!echo '{"username":"YOUR_KAGGLE_USERNAME","key":"YOUR_KAGGLE_KEY"}' > ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json
!kaggle competitions download -c titanic

!unzip titanic.zip
df = pd.read_csv('/content/train.csv')
print(df.head())

"""
ðŸŒŸ Exercise 4: Importing a CSV File
Use the Iris Dataset CSV.

Download the Iris dataset CSV file and place it in the same directory as your Jupyter Notebook.
Import the CSV file using Pandas.
Display the first five rows of the dataset.
"""

import pandas as pd

try:
  df_iris = pd.read_csv('iris_dataset.csv')
  print(df_iris.head())
except FileNotFoundError:
  print("Error: 'iris.csv' not found. Please make sure the file is in the same directory as the notebook.")
except Exception as e:
  print(f"An error occurred: {e}")

"""
ðŸŒŸ Exercise 5 : Export a dataframe to excel format and JSON format.
Create a simple dataframe.
Export the dataframe to an excel file.
Export the dataframe to a JSON file.
"""

import pandas as pd
# Create a sample DataFrame
data = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}
df_sample = pd.DataFrame(data)

# Export to Excel
df_sample.to_excel('output.xlsx', index=False)  # index=False prevents row indices from being written

# Export to JSON
df_sample.to_json('output.json', orient='records') # orient='records' creates a list of JSON objects

""" Exercise 6: Reading JSON Data
Use a sample JSON dataset

Import the JSON data from the provided URL.
Use Pandas to read the JSON data.
Display the first five entries of the data.

"""

import pandas as pd

# Sample JSON data (replace with your actual URL or JSON file path)
json_url = "your_json_file_url_or_path.json"

try:
    df_json = pd.read_json(json_url)
    print(df_json.head())
except FileNotFoundError:
    print(f"Error: File not found at '{json_url}'. Please check the path.")
except ValueError as e:
    print(f"Error reading JSON data: {e}")
except Exception as e:
    print(f"An unexpected error occurred: {e}")