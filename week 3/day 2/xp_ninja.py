# -*- coding: utf-8 -*-
"""xp ninja

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S4xuRP7OTbzLOECR4fCtqjrp-qz9kQDm

Exercise 1 : Comparative Analysis of Structured and Unstructured Data
Given two datasets - one structured, a CSV file of product sales data and one unstructured, a collection of customer support tickets, perform a basic analysis on each.
Identify the challenges faced while processing the unstructured dataset as compared to the structured dataset.
Describe the tools and techniques that were effective for each type of data.
Hint: Sentiment Analysis using TextBlob
"""

!pip install textblob
import pandas as pd
from textblob import TextBlob

# Sample structured data (replace with your actual CSV file)
sales_data = {
    'Product': ['A', 'B', 'A', 'C', 'B'],
    'Sales': [10, 15, 12, 8, 20]
}
sales_df = pd.DataFrame(sales_data)


# Sample unstructured data (replace with your actual customer support tickets)
support_tickets = [
    "The product is great!",
    "I am very unhappy with the customer service.",
    "The delivery was delayed.",
    "Good product, but the website is slow."
]


# Analysis of structured data
print("\nAnalysis of Structured Data (Sales Data):")
print(sales_df.describe())
print("\nProduct A sales:", sales_df[sales_df['Product'] == 'A']['Sales'].sum())


# Analysis of unstructured data
print("\nAnalysis of Unstructured Data (Customer Support Tickets):")

sentiments = []
for ticket in support_tickets:
  analysis = TextBlob(ticket)
  sentiments.append(analysis.sentiment.polarity)

print("Sentiments:", sentiments)
average_sentiment = sum(sentiments) / len(sentiments)
print(f"Average sentiment: {average_sentiment}")


# Challenges and techniques
print("\nComparative Analysis:")
print("Structured Data (CSV):")
print("- Challenges:  Minimal challenges for processing and analysis. Data is well-organized and easily queried.")
print("- Techniques:  Pandas for data manipulation and analysis, descriptive statistics, aggregations.")

print("\nUnstructured Data (Customer Support Tickets):")
print("- Challenges:  Cleaning the text, dealing with noise, inconsistencies, and variations in language. Extracting meaningful information and quantifying sentiment requires specific techniques.")
print("- Techniques: TextBlob for sentiment analysis, regular expressions for text cleaning, topic modeling (e.g., Latent Dirichlet Allocation - LDA) for grouping similar tickets.")

"""
Exercise 2 : Converting Unstructured Data to Structured Data
Here is an unstructured dataset containing tweets.

Apply text processing techniques to extract key information (such as hashtags and mentions, you already have a column “sentiment”) from the dataset.
Organize this extracted information into a structured format (like a table with columns for each key information type).
Perform a basic analysis on the newly structured data and compare insights with the original unstructured format.
"""

import pandas as pd
import re

def extract_info(text):
    hashtags = re.findall(r"#(\w+)", text)
    mentions = re.findall(r"@(\w+)", text)
    return hashtags, mentions


structured_data = []
for ticket in support_tickets:
    hashtags, mentions = extract_info(ticket)
    analysis = TextBlob(ticket)
    sentiment = analysis.sentiment.polarity
    structured_data.append({
        'text': ticket,
        'hashtags': hashtags,
        'mentions': mentions,
        'sentiment': sentiment
    })

structured_df = pd.DataFrame(structured_data)
print("\nStructured Data (from unstructured tweets):")
print(structured_df)

# Analysis of structured data
print("\nAnalysis of newly structured data:")
print("Number of tickets with positive sentiment:", len(structured_df[structured_df['sentiment'] > 0]))
hashtag_counts = {}
for index, row in structured_df.iterrows():
    for hashtag in row['hashtags']:
      hashtag_counts[hashtag] = hashtag_counts.get(hashtag, 0) + 1

print("\nHashtag counts:")
for hashtag, count in hashtag_counts.items():
    print(f"{hashtag}: {count}")